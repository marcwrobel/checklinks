#!/usr/bin/env bash

set -uo pipefail

USER_AGENT='Mozilla/5.0 (X11; Linux x86_64; rv:91.0) Gecko/20100101 Firefox/91.0'
RETRY=1
RETRY_DELAY=10
TIMEOUT=3 # seconds

URL_REGEX='https?://[^][{} "`<>),*$|\\]*[^][{} "`<>),*$|\\.:'"'"']'
EXCLUDED_URLS="https?://(\
localhost|\
old.nabble.com|\
news.gmane.org|\
[0-9]+|\
.+:[0-9]+|\
example|\
[^/]+.example|\
host|\
somehost|\
nohost|\
link|\
acme.org|\
foo|\
application|\
registry.npmjs.org|\
apache.org/xml/features|\
java.sun.com/xml/ns|\
javax.xml.XMLConstants)"

RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

function doCurl() {
  curl -o /dev/null --silent --connect-timeout "$TIMEOUT" --retry $RETRY --retry-delay $RETRY_DELAY --user-agent "$USER_AGENT" --location --write-out '%{http_code}' "$1"
}

[ ! -d "$1" ] && echo "'$1'  is not a directory" && exit 1

URLS_AND_FILES=$(grep -RioE --exclude-dir={.git,.idea,target,output} --exclude=*.{class,svg} "$URL_REGEX" .)

# Links are processed in a random order to reduce the risk of being blacklisted and temporarily blocked
for url in $(echo "$URLS_AND_FILES" | cut -d ':' -f 2- | sort | uniq | sort -R); do
  if [[ "$url" =~ $EXCLUDED_URLS ]]; then
    echo -e "${GREEN}$url (IGNORED)${NC}"

  else
    # we could use --head, but it is not always supported...
    status=$(doCurl "$url")

    if [ "$status" = "200" ]; then
      if [[ $url =~ "http://" ]]; then
        https_status=$(doCurl "${url/http:\/\//https:\/\/}")
        if [ "$https_status" = "200" ]; then
          echo -e "${BLUE}$url ($status - HTTPS OK)${NC}"
        else
          echo -e "${BLUE}$url ($status - HTTPS KO)${NC}"
        fi
      else
        echo -e "${GREEN}$url ($status)${NC}"
      fi
    else
      echo -e "${RED}$url ($status)${NC}"
    fi
  fi
done
